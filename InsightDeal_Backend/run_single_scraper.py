import time
from contextlib import contextmanager
from datetime import datetime
from database import db_manager
from logger import logger
from config import config

# ë‹¨ì¼ ìŠ¤í¬ë˜í¼ import
from scrapers.alippomppu_scraper import AlippomppuScraper
from scrapers.ruliweb_scraper import RuliwebScraper
from scrapers.ppomppu_scraper import PpomppuScraper
from scrapers.ppomppu_overseas_scraper import PpomppuOverseasScraper
from scrapers.bbasak_domestic_scraper import BbasakDomesticScraper
from scrapers.bbasak_overseas_scraper import BbasakOverseasScraper
from scrapers.clien_scraper import ClienScraper
from scrapers.quasarzone_scraper import QuasarzoneScraper
from scrapers.fmkorea_scraper import FmkoreaScraper

class SingleScraperTester:
    """ë‹¨ì¼ ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self, scraper_class):
        self.scraper_class = scraper_class
        self.scraper_name = scraper_class.__name__
        self.start_time = None
        self.success = False
    
    @contextmanager
    def execution_tracker(self):
        """ì‹¤í–‰ ì¶”ì  ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        self.start_time = datetime.now()
        logger.info(f"[START] {self.scraper_name} í…ŒìŠ¤íŠ¸ ì‹œì‘: {self.start_time}")
        
        try:
            yield
        finally:
            elapsed = datetime.now() - self.start_time
            status = "[SUCCESS]" if self.success else "[FAILED]"
            logger.info(f"{status} {self.scraper_name} í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ì†Œìš”ì‹œê°„: {elapsed}")
    
    def run_test(self, limit: int = 5) -> bool:
        """ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        try:
            with self.execution_tracker():
                with db_manager.get_session() as db_session:
                    with self.scraper_class(db_session) as scraper:
                        # ìŠ¤í¬ë˜í¼ ì‹¤í–‰
                        self.success = scraper.run(limit=limit)
                        
                        # ê²°ê³¼ ìƒì„¸ ì •ë³´ ì¶œë ¥
                        if self.success:
                            logger.info(f"[SUCCESS] {self.scraper_name} - {limit}ê°œ í•œë„ë¡œ ì‹¤í–‰ ì™„ë£Œ")
                        else:
                            logger.warning(f"[FAILED] {self.scraper_name} - ì‹¤í–‰ ì‹¤íŒ¨")
                        
                        return self.success
                        
        except Exception as e:
            logger.error(f"[ERROR] {self.scraper_name} í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
            self.success = False
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ§ª PpomppuOverseasScraper ë‹¨ë… í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸í•  ìŠ¤í¬ë˜í¼ ì„¤ì •
    scraper_to_test = PpomppuOverseasScraper
    limit = 3  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 5ê°œë§Œ
    
    # í…ŒìŠ¤í„° ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì‹¤í–‰
    tester = SingleScraperTester(scraper_to_test)
    success = tester.run_test(limit=limit)
    
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("=" * 60)
    if success:
        print(f"âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ! {scraper_to_test.__name__}")
        print("ğŸ” APIì—ì„œ ìƒˆë¡œìš´ ë”œì„ í™•ì¸í•´ë³´ì„¸ìš”:")
        print("   curl http://localhost:8000/api/deals")
        print("   ë˜ëŠ” ì•±ì—ì„œ ìƒˆë¡œê³ ì¹¨!")
    else:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨! {scraper_to_test.__name__}")
        print("ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ì˜¤ë¥˜ë¥¼ ë¶„ì„í•˜ì„¸ìš”.")
    print("=" * 60)

if __name__ == "__main__":
    main()
