"""
ğŸš€ InsightDeal FastAPI ì„œë²„ - 4ëª° í†µí•© ê°€ê²© ë¹„êµ API + ë„¤ì´ë²„ ì‡¼í•‘ API

ì‚¬ìš©ì ì¤‘ì‹¬ ì„¤ê³„:
- 2ì´ˆ ë‚´ 4ëª° ê°€ê²© ë¹„êµ ì‘ë‹µ (ì‚¬ìš©ìëŠ” ê¸°ë‹¤ë¦¬ì§€ ì•ŠëŠ”ë‹¤)
- ì‹¤íŒ¨í•´ë„ ì‚¬ìš©ì ê²½í—˜ ë°©í•´ ì—†ìŒ (ìµœì†Œ 2ê°œ í”Œë«í¼ ì„±ê³µ ì‹œ ê²°ê³¼ ì œê³µ)
- ìƒì„¸í•œ ë¡œê¹…ìœ¼ë¡œ ë¬¸ì œ ë°œìƒ ì‹œ ì¦‰ì‹œ ì¶”ì  ê°€ëŠ¥
- ìºì‹œë¡œ ë°˜ë³µ ìš”ì²­ ì‹œ ì¦‰ì‹œ ì‘ë‹µ
- ë„¤ì´ë²„ ì‡¼í•‘ APIë¡œ ì•ˆì •ì ì¸ ê²€ìƒ‰ ê²°ê³¼ ë³´ì¥

"ë§¤ì¼ ì“°ê³  ì‹¶ì€ ì•±"ì„ ìœ„í•œ ì•ˆì •ì ì´ê³  ë¹ ë¥¸ ë°±ì—”ë“œ
"""

import asyncio
import json
import time
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException, Query, Request, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn
import logging
import structlog
from pydantic import BaseModel

from scrapers.base_scraper import PriceComparisonEngine, ProductInfo
from scrapers.coupang_scraper import CoupangScraper
from scrapers.eleventh_scraper import EleventhScraper
from scrapers.gmarket_scraper import GmarketScraper
from scrapers.auction_scraper import AuctionScraper

# ë„¤ì´ë²„ ì‡¼í•‘ API ìŠ¤í¬ë˜í¼ import
from scrapers.naver_shopping_scraper import NaverShoppingScraper

# ğŸ¯ ì‚¬ìš©ì ì¤‘ì‹¬ ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(name)s | %(levelname)s | %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)

# êµ¬ì¡°í™”ëœ ë¡œê¹… (JSON í˜•íƒœë¡œ íŒŒì‹± ê°€ëŠ¥)
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="%Y-%m-%d %H:%M:%S"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger("insightdeal.api")

# ê¸€ë¡œë²Œ ê°€ê²© ë¹„êµ ì—”ì§„
price_engine = PriceComparisonEngine()

# ë„¤ì´ë²„ ì‡¼í•‘ API ìŠ¤í¬ë˜í¼ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
naver_scraper = None

# ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (ë„¤ì´ë²„ ì‡¼í•‘ ì¶”ê°€)
metrics = {
    "total_requests": 0,
    "successful_requests": 0,
    "failed_requests": 0,
    "avg_response_time": 0.0,
    "cache_hits": 0,
    "platform_success_rates": {
        "coupang": {"success": 0, "total": 0},
        "eleventh": {"success": 0, "total": 0},
        "gmarket": {"success": 0, "total": 0},
        "auction": {"success": 0, "total": 0},
        "naver_shopping": {"success": 0, "total": 0}  # ë„¤ì´ë²„ ì‡¼í•‘ ì¶”ê°€
    }
}

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    ğŸƒâ€â™€ï¸ ì„œë²„ ì‹œì‘ ì‹œ 4ê°œ ìŠ¤í¬ë˜í¼ + ë„¤ì´ë²„ ì‡¼í•‘ API ë“±ë¡
    ì‚¬ìš©ìì—ê²Œ ì•ˆì •ì ì¸ ì„œë¹„ìŠ¤ ì œê³µì„ ìœ„í•œ ì´ˆê¸°í™”
    """
    global naver_scraper
    start_time = time.time()
    
    try:
        # 4ëª° ìŠ¤í¬ë˜í¼ ë“±ë¡ (ê¸°ì¡´ ì›¹ ìŠ¤í¬ë˜í•‘, ì°¨ë‹¨ë  ê°€ëŠ¥ì„± ìˆìŒ)
        scrapers = [
            ("coupang", CoupangScraper),
            ("eleventh", EleventhScraper),
            ("gmarket", GmarketScraper),
            ("auction", AuctionScraper)
        ]
        
        for name, scraper_class in scrapers:
            try:
                price_engine.register_scraper(name, scraper_class())
                logger.info(f"âœ… {name} scraper ë“±ë¡ ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"âš ï¸ {name} scraper ë“±ë¡ ì‹¤íŒ¨: {e}")
        
        # ë„¤ì´ë²„ ì‡¼í•‘ API ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™” (í•µì‹¬!)
        try:
            naver_scraper = NaverShoppingScraper()
            logger.info("âœ… Naver Shopping API scraper ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ Naver Shopping API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            naver_scraper = None
        
        init_time = time.time() - start_time
        total_scrapers = len(price_engine.scrapers) + (1 if naver_scraper else 0)
        
        logger.info(
            "ì„œë²„ ì´ˆê¸°í™” ì™„ë£Œ", 
            scrapers_count=total_scrapers,
            init_time_ms=round(init_time * 1000, 2),
            platforms=list(price_engine.scrapers.keys()) + (["naver_shopping"] if naver_scraper else [])
        )
        
        yield  # ì„œë²„ ì‹¤í–‰
        
    except Exception as e:
        logger.error(
            "ì„œë²„ ì´ˆê¸°í™” ì‹¤íŒ¨",
            error=str(e),
            elapsed_ms=round((time.time() - start_time) * 1000, 2)
        )
        raise
    finally:
        logger.info("ì„œë²„ ì¢…ë£Œ", final_metrics=metrics)

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="InsightDeal API",
    description="ğŸ›’ êµ­ë‚´ ìµœì´ˆ 4ëª° í†µí•© ê°€ê²©ë¹„êµ API + ë„¤ì´ë²„ ì‡¼í•‘ API\nì‚¬ìš©ì ì¤‘ì‹¬: 2ì´ˆ ë‚´ ì‘ë‹µ + ì‹¤ì‹œê°„ ìµœì €ê°€ ë°œê²¬",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì • (Android ì•± ì—°ë™)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class ComparisonResponse(BaseModel):
    """
    ğŸ“Š 4ëª° + ë„¤ì´ë²„ ì‡¼í•‘ ê°€ê²© ë¹„êµ ì‘ë‹µ ëª¨ë¸
    ì‚¬ìš©ìê°€ ë°›ê³  ì‹¶ì–´í•˜ëŠ” í•µì‹¬ ì •ë³´ë§Œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ
    """
    trace_id: str
    query: str
    platforms: Dict[str, Dict[str, Any]]
    lowest_platform: Optional[str]
    lowest_price: Optional[int] 
    max_saving: int  # ì‚¬ìš©ìê°€ ê°€ì¥ ê´€ì‹¬ ìˆëŠ” "ì–¼ë§ˆë‚˜ ì•„ë‚„ ìˆ˜ ìˆëŠ”ì§€"
    average_price: Optional[int]
    success_count: int
    total_platforms: int
    response_time_ms: int
    updated_at: str
    errors: List[str] = []  # ë¬¸ì œ ë°œìƒ ì‹œì—ë„ ì‚¬ìš©ìì—ê²ŒëŠ” ìˆ¨ê¸°ê³  ë¡œê·¸ë¡œë§Œ

def _generate_trace_id() -> str:
    """
    ğŸ” ìš”ì²­ ì¶”ì  ID ìƒì„± (ë¬¸ì œ ë°œìƒ ì‹œ end-to-end ì¶”ì ìš©)
    """
    return f"trace_{int(time.time())}_{uuid.uuid4().hex[:8]}"

def _clean_query(query: str) -> str:
    """
    ğŸ§¹ ì‚¬ìš©ì ì…ë ¥ ì¿¼ë¦¬ ì •ì œ (ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ)
    """
    if not query:
        return ""
    # ê³µë°± ì •ë¦¬, íŠ¹ìˆ˜ë¬¸ì ì œê±°, ê¸¸ì´ ì œí•œ
    cleaned = " ".join(query.strip().split())
    return cleaned[:50]  # ë„ˆë¬´ ê¸´ ì¿¼ë¦¬ëŠ” ì˜ë¼ì„œ ì„±ëŠ¥ í™•ë³´

def _update_platform_metrics(platform: str, success: bool):
    """
    ğŸ“ˆ í”Œë«í¼ë³„ ì„±ê³µë¥  ì¶”ì  (ìš´ì˜ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§)
    """
    if platform in metrics["platform_success_rates"]:
        metrics["platform_success_rates"][platform]["total"] += 1
        if success:
            metrics["platform_success_rates"][platform]["success"] += 1

@app.middleware("http")
async def log_requests(request: Request, call_next):
    """
    ğŸ“ ëª¨ë“  API ìš”ì²­ ë¡œê¹… (ë¬¸ì œ ë°œìƒ ì‹œ ì¶”ì ì„ ìœ„í•´)
    """
    start_time = time.time()
    trace_id = _generate_trace_id()
    
    # ìš”ì²­ ë¡œê·¸
    logger.info(
        "API ìš”ì²­ ì‹œì‘",
        trace_id=trace_id,
        method=request.method,
        url=str(request.url),
        user_agent=request.headers.get("user-agent", "unknown")
    )
    
    # ìš”ì²­ ì²˜ë¦¬
    response = await call_next(request)
    
    # ì‘ë‹µ ë¡œê·¸
    elapsed_ms = round((time.time() - start_time) * 1000, 2)
    logger.info(
        "API ìš”ì²­ ì™„ë£Œ",
        trace_id=trace_id,
        status_code=response.status_code,
        elapsed_ms=elapsed_ms,
        success=200 <= response.status_code < 300
    )
    
    response.headers["X-Trace-ID"] = trace_id
    return response

@app.get("/api/health")
async def health_check():
    """
    â¤ï¸ í—¬ìŠ¤ì²´í¬ - ì„œë²„ ìƒíƒœ ë° ì„±ëŠ¥ ì§€í‘œ í™•ì¸
    """
    total_scrapers = len(price_engine.scrapers) + (1 if naver_scraper else 0)
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "scrapers": total_scrapers,
        "metrics": metrics
    }

@app.get("/api/compare", response_model=ComparisonResponse)
async def compare_prices(
    query: str = Query(..., description="ìƒí’ˆëª… (ì˜ˆ: ê°¤ëŸ­ì‹œ ë²„ì¦ˆ í”„ë¡œ)", max_length=50),
    trace_id: str = None
):
    """
    ğŸ”¥ 4ëª° + ë„¤ì´ë²„ ì‡¼í•‘ ê°€ê²© ë¹„êµ - ì‚¬ìš©ìê°€ ê°€ì¥ ë§ì´ ì‚¬ìš©í•  í•µì‹¬ API
    
    ì‚¬ìš©ì ê²½í—˜ ìš°ì„ ìˆœìœ„:
    1. ë¹ ë¥¸ ì‘ë‹µ (2ì´ˆ ëª©í‘œ) 
    2. ìµœì €ê°€ ì •ë³´ ì •í™•ì„±
    3. ì‹¤íŒ¨í•´ë„ ì‚¬ìš© ê°€ëŠ¥í•œ ê²°ê³¼ ì œê³µ (ë„¤ì´ë²„ ì‡¼í•‘ API ë•ë¶„ì— ê°€ëŠ¥)
    """
    start_time = time.time()
    if not trace_id:
        trace_id = _generate_trace_id()
    
    metrics["total_requests"] += 1
    
    # ì‚¬ìš©ì ì…ë ¥ ê²€ì¦ ë° ì •ì œ
    clean_query = _clean_query(query)
    if not clean_query:
        logger.warning("ë¹ˆ ì¿¼ë¦¬ ìš”ì²­", trace_id=trace_id, original_query=query)
        raise HTTPException(status_code=400, detail="ìƒí’ˆëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”")
    
    logger.info(
        "ê°€ê²© ë¹„êµ ì‹œì‘", 
        trace_id=trace_id, 
        query=clean_query,
        target_time_ms=2000,
        total_platforms=len(price_engine.scrapers) + (1 if naver_scraper else 0)
    )
    
    try:
        platforms_data = {}
        errors = []
        success_count = 0
        
        # ğŸš€ 1ìˆœìœ„: ë„¤ì´ë²„ ì‡¼í•‘ API (ê°€ì¥ ì•ˆì •ì )
        if naver_scraper:
            try:
                naver_products = naver_scraper.search_products(clean_query, display=10, sort="asc")
                
                if naver_products:
                    # ë„¤ì´ë²„ ì‡¼í•‘ ê²°ê³¼ë¥¼ ê¸°ì¡´ êµ¬ì¡°ì— ë§ê²Œ ë³€í™˜
                    formatted_products = []
                    for product in naver_products[:5]:  # ìƒìœ„ 5ê°œë§Œ
                        formatted_product = {
                            "title": product.title,
                            "price": product.price,
                            "original_price": product.price,
                            "discount_rate": 0,
                            "url": product.url,
                            "shipping_fee": 0,
                            "seller": product.mall,
                            "rating": 0,
                            "is_available": True,
                            "image": product.image,
                            "mall": product.mall,
                            "category": product.category1 or "ì¼ë°˜"
                        }
                        formatted_products.append(formatted_product)
                    
                    platforms_data["naver_shopping"] = {
                        "products": formatted_products,
                        "count": len(formatted_products),
                        "status": "success",
                        "source": "naver_api",
                        "response_time_ms": int((time.time() - start_time) * 1000)
                    }
                    
                    success_count += 1
                    _update_platform_metrics("naver_shopping", True)
                    
                    logger.info(
                        "ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰ ì„±ê³µ",
                        trace_id=trace_id,
                        query=clean_query,
                        products_count=len(naver_products),
                        elapsed_ms=int((time.time() - start_time) * 1000)
                    )
                else:
                    platforms_data["naver_shopping"] = {
                        "products": [],
                        "count": 0,
                        "status": "no_results",
                        "source": "naver_api"
                    }
                    errors.append("ë„¤ì´ë²„ ì‡¼í•‘: ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                    _update_platform_metrics("naver_shopping", False)
                    
            except Exception as e:
                logger.error(
                    "ë„¤ì´ë²„ ì‡¼í•‘ API ì˜¤ë¥˜",
                    trace_id=trace_id,
                    query=clean_query,
                    error=str(e)
                )
                platforms_data["naver_shopping"] = {
                    "products": [],
                    "count": 0,
                    "status": "error",
                    "error": str(e),
                    "source": "naver_api"
                }
                errors.append(f"ë„¤ì´ë²„ ì‡¼í•‘ API ì˜¤ë¥˜: {str(e)}")
                _update_platform_metrics("naver_shopping", False)
        
        # ğŸ•¸ï¸ 2ìˆœìœ„: ê¸°ì¡´ 4ëª° ì›¹ ìŠ¤í¬ë˜í•‘ (ì°¨ë‹¨ë  ê°€ëŠ¥ì„± ë†’ìŒ)
        try:
            comparison_result = await price_engine.compare_prices(clean_query)
            
            if comparison_result and comparison_result.platforms:
                for platform, product_info in comparison_result.platforms.items():
                    if product_info:
                        platforms_data[platform] = {
                            "price": product_info.current_price,
                            "original_price": product_info.original_price,
                            "discount_rate": product_info.discount_rate,
                            "url": product_info.product_url,
                            "shipping_fee": product_info.shipping_fee,
                            "seller": product_info.seller_name,
                            "rating": product_info.rating,
                            "is_available": product_info.is_available,
                            "source": "web_scraping"
                        }
                        success_count += 1
                        _update_platform_metrics(platform, True)
                    else:
                        _update_platform_metrics(platform, False)
                        errors.append(f"{platform} ê²€ìƒ‰ ì‹¤íŒ¨ (ì°¨ë‹¨ ê°€ëŠ¥ì„±)")
            else:
                logger.info(
                    "ê¸°ì¡´ 4ëª° ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ (ì˜ˆìƒë¨)",
                    trace_id=trace_id,
                    query=clean_query,
                    reason="ì›¹ ìŠ¤í¬ë˜í•‘ ì°¨ë‹¨")
                
        except Exception as e:
            logger.warning(
                "4ëª° ì›¹ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ (ì˜ˆìƒë¨)",
                trace_id=trace_id,
                query=clean_query,
                error=str(e)
            )
            errors.append("ì›¹ ìŠ¤í¬ë˜í•‘ ì°¨ë‹¨ìœ¼ë¡œ ì¸í•œ ì¼ë¶€ ëª° ê²€ìƒ‰ ì‹¤íŒ¨")
        
        # ğŸ“Š ì‚¬ìš©ìê°€ ì›í•˜ëŠ” í•µì‹¬ ì •ë³´ ê³„ì‚°
        all_prices = []
        lowest_price = None
        lowest_platform = None
        
        for platform, data in platforms_data.items():
            if data.get("status") == "success":
                if data.get("products"):  # ë„¤ì´ë²„ ì‡¼í•‘ í˜•íƒœ
                    for product in data["products"]:
                        price = product.get("price", 0)
                        if price > 0:
                            all_prices.append(price)
                            if lowest_price is None or price < lowest_price:
                                lowest_price = price
                                lowest_platform = platform
                elif data.get("price"):  # ê¸°ì¡´ ìŠ¤í¬ë˜í¼ í˜•íƒœ
                    price = data["price"]
                    if price > 0:
                        all_prices.append(price)
                        if lowest_price is None or price < lowest_price:
                            lowest_price = price
                            lowest_platform = platform
        
        # ì ˆì•½ ê¸ˆì•¡ ê³„ì‚°
        max_saving = 0
        average_price = None
        
        if len(all_prices) >= 2:
            max_saving = max(all_prices) - min(all_prices)
            average_price = sum(all_prices) // len(all_prices)
        elif len(all_prices) == 1:
            average_price = all_prices[0]
        
        elapsed_ms = round((time.time() - start_time) * 1000, 2)
        
        # ì„±ê³µ/ì‹¤íŒ¨ íŒì •
        if success_count > 0:
            metrics["successful_requests"] += 1
            
            logger.info(
                "ê°€ê²© ë¹„êµ ì„±ê³µ",
                trace_id=trace_id,
                query=clean_query,
                success_count=success_count,
                lowest_platform=lowest_platform,
                lowest_price=lowest_price,
                max_saving=max_saving,
                elapsed_ms=elapsed_ms,
                naver_success=naver_scraper is not None and "naver_shopping" in platforms_data
            )
        else:
            metrics["failed_requests"] += 1
            
            logger.warning(
                "ëª¨ë“  í”Œë«í¼ ê²€ìƒ‰ ì‹¤íŒ¨",
                trace_id=trace_id,
                query=clean_query,
                elapsed_ms=elapsed_ms,
                errors=errors
            )
            
            if not errors:
                errors = ["ëª¨ë“  ì‡¼í•‘ëª°ì—ì„œ ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"]
        
        # í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸
        total_requests = metrics["successful_requests"] + metrics["failed_requests"]
        metrics["avg_response_time"] = (
            (metrics["avg_response_time"] * (total_requests - 1) + elapsed_ms) / total_requests
        )
        
        return ComparisonResponse(
            trace_id=trace_id,
            query=clean_query,
            platforms=platforms_data,
            lowest_platform=lowest_platform,
            lowest_price=lowest_price,
            max_saving=max_saving,
            average_price=average_price,
            success_count=success_count,
            total_platforms=len(price_engine.scrapers) + (1 if naver_scraper else 0),
            response_time_ms=int(elapsed_ms),
            updated_at=datetime.now().isoformat(),
            errors=errors
        )
        
    except Exception as e:
        elapsed_ms = round((time.time() - start_time) * 1000, 2)
        logger.error(
            "ê°€ê²© ë¹„êµ ì˜ˆì™¸ ë°œìƒ",
            trace_id=trace_id,
            query=clean_query,
            error=str(e),
            elapsed_ms=elapsed_ms,
            exc_info=True
        )
        
        metrics["failed_requests"] += 1
        
        # ì‚¬ìš©ìì—ê²ŒëŠ” ì¹œí™”ì ì¸ ë©”ì‹œì§€, ê°œë°œìì—ê²ŒëŠ” ìƒì„¸ ë¡œê·¸
        raise HTTPException(
            status_code=500, 
            detail="ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”"
        )

if __name__ == "__main__":
    # ğŸš€ ì„œë²„ ì‹¤í–‰ (ì‚¬ìš©ì ì‘ë‹µì†ë„ ìµœì í™” ì„¤ì •)
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,  # ê°œë°œ ì‹œì—ë§Œ
        workers=1,    # ê°œë°œ ì‹œì—ë§Œ, í”„ë¡œë•ì…˜ì—ì„œëŠ” 4+ ê¶Œì¥
        log_level="info",
        access_log=True
    )