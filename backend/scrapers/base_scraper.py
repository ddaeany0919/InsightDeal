"""
ğŸ—ï¸ BaseScraper - 4ê°œ ì‡¼í•‘ëª° í†µí•© ìŠ¤í¬ë˜í¼ ê¸°ë³¸ í´ë˜ìŠ¤

êµ­ë‚´ ìµœì´ˆ 4ëª° í†µí•© ê°€ê²© ë¹„êµë¥¼ ìœ„í•œ ê³µí†µ ì¸í„°í˜ì´ìŠ¤
- ì¿ íŒ¡, 11ë²ˆê°€, Gë§ˆì¼“, ì˜¥ì…˜ ëª¨ë‘ ì§€ì›
- ì—ëŸ¬ ì²˜ë¦¬, ë¡œê¹…, Rate Limiting í¬í•¨
- ì‚¬ìš©ì ì¤‘ì‹¬: "ë§¤ì¼ ì“°ê³  ì‹¶ì€ ì•±"ì„ ìœ„í•œ ì•ˆì •ì„± í™•ë³´
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Union
import asyncio
import aiohttp
import time
import logging
from datetime import datetime, timedelta
from dataclasses import dataclass
import re

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ProductInfo:
    """ğŸ›ï¸ ìƒí’ˆ ì •ë³´ í‘œì¤€ ë°ì´í„° í´ë˜ìŠ¤"""
    platform: str           # í”Œë«í¼ëª… (coupang, eleventh, gmarket, auction)
    product_name: str        # ìƒí’ˆëª…
    current_price: int       # í˜„ì¬ ê°€ê²©
    original_price: int      # ì›ê°€ (í• ì¸ ì „)
    discount_rate: int       # í• ì¸ìœ¨ (%)
    product_url: str         # ìƒí’ˆ ë§í¬
    image_url: str           # ìƒí’ˆ ì´ë¯¸ì§€
    shipping_fee: int        # ë°°ì†¡ë¹„ (0ì´ë©´ ë¬´ë£Œë°°ì†¡)
    rating: float            # í‰ì  (0-5)
    review_count: int        # ë¦¬ë·° ìˆ˜
    seller_name: str         # íŒë§¤ìëª…
    is_available: bool       # ì¬ê³  ì—¬ë¶€
    updated_at: datetime     # ìˆ˜ì§‘ ì‹œê°„
    
@dataclass 
class PriceComparison:
    """ğŸ“Š 4ëª° ê°€ê²© ë¹„êµ ê²°ê³¼"""
    product_name: str
    platforms: Dict[str, ProductInfo]
    lowest_platform: str
    lowest_price: int
    max_saving: int          # ìµœëŒ€ ì ˆì•½ ê¸ˆì•¡
    average_price: int       # í‰ê·  ê°€ê²©
    last_updated: datetime

class BaseScraper(ABC):
    """ğŸ—ï¸ 4ëª° í†µí•© ìŠ¤í¬ë˜í¼ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, platform_name: str):
        self.platform_name = platform_name
        self.session = None
        self.last_request_time = 0
        self.min_delay = 1.0  # ìµœì†Œ ìš”ì²­ ê°„ê²© (ì´ˆ)
        self.max_retries = 3  # ìµœëŒ€ ì¬ì‹œë„
        
    async def __aenter__(self):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=30),
            headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
            }
        )
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        if self.session:
            await self.session.close()
    
    def _respect_rate_limit(self):
        """â±ï¸ Rate Limiting ì¤€ìˆ˜"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        if time_since_last < self.min_delay:
            sleep_time = self.min_delay - time_since_last
            logger.info(f"ğŸ• {self.platform_name} Rate limiting: {sleep_time:.1f}ì´ˆ ëŒ€ê¸°")
            time.sleep(sleep_time)
        self.last_request_time = time.time()
    
    def _clean_price(self, price_text: str) -> int:
        """ğŸ’° ê°€ê²© í…ìŠ¤íŠ¸ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜"""
        if not price_text:
            return 0
        # ìˆ«ìë§Œ ì¶”ì¶œ
        numbers = re.findall(r'\d+', str(price_text).replace(',', ''))
        if numbers:
            return int(''.join(numbers))
        return 0
    
    def _clean_product_name(self, name: str) -> str:
        """ğŸ§¹ ìƒí’ˆëª… ì •ë¦¬ (ë¸Œëœë“œëª…/ëª¨ë¸ëª… ì¶”ì¶œ)"""
        if not name:
            return ""
        # HTML íƒœê·¸ ì œê±°
        clean_name = re.sub(r'<[^>]+>', '', name)
        # íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
        clean_name = re.sub(r'[^\w\sê°€-í£]', ' ', clean_name)
        # ê³µë°± ì •ë¦¬
        return ' '.join(clean_name.split())
    
    async def _make_request(self, url: str, method: str = 'GET', **kwargs) -> Optional[Union[str, dict]]:
        """ğŸŒ HTTP ìš”ì²­ (ì¬ì‹œë„ + ì—ëŸ¬ ì²˜ë¦¬)"""
        self._respect_rate_limit()
        
        for attempt in range(self.max_retries):
            try:
                if method.upper() == 'GET':
                    async with self.session.get(url, **kwargs) as response:
                        if response.status == 200:
                            return await response.text()
                        else:
                            logger.warning(f"âš ï¸ {self.platform_name} HTTP {response.status}: {url}")
                            
                elif method.upper() == 'POST':
                    async with self.session.post(url, **kwargs) as response:
                        if response.status == 200:
                            return await response.json()
                            
            except Exception as e:
                logger.error(f"âŒ {self.platform_name} ìš”ì²­ ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{self.max_retries}): {e}")
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                    
        return None
    
    @abstractmethod
    async def search_product(self, product_name: str, limit: int = 10) -> List[ProductInfo]:
        """ğŸ” ìƒí’ˆ ê²€ìƒ‰ (ì¶”ìƒ ë©”ì†Œë“œ)"""
        pass
    
    @abstractmethod  
    async def get_product_detail(self, product_url: str) -> Optional[ProductInfo]:
        """ğŸ“‹ ìƒí’ˆ ìƒì„¸ ì •ë³´ (ì¶”ìƒ ë©”ì†Œë“œ)"""
        pass
    
    async def get_price_only(self, product_url: str) -> Optional[int]:
        """ğŸ’° ê°€ê²©ë§Œ ë¹ ë¥´ê²Œ ì¡°íšŒ"""
        try:
            product = await self.get_product_detail(product_url)
            return product.current_price if product else None
        except Exception as e:
            logger.error(f"âŒ {self.platform_name} ê°€ê²© ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    def is_valid_url(self, url: str) -> bool:
        """âœ… í”Œë«í¼ë³„ URL ìœ íš¨ì„± ê²€ì¦"""
        platform_domains = {
            'coupang': 'coupang.com',
            'eleventh': '11st.co.kr', 
            'gmarket': 'gmarket.co.kr',
            'auction': 'auction.co.kr'
        }
        domain = platform_domains.get(self.platform_name.lower())
        return domain in url if domain else False

class PriceComparisonEngine:
    """ğŸ“Š 4ëª° ê°€ê²© ë¹„êµ ì—”ì§„"""
    
    def __init__(self):
        self.scrapers = {}
        self.cache = {}  # ë‹¨ìˆœ ë©”ëª¨ë¦¬ ìºì‹œ (5ë¶„)
        self.cache_duration = 300  # 5ë¶„
    
    def register_scraper(self, platform: str, scraper: BaseScraper):
        """ğŸ”§ ìŠ¤í¬ë˜í¼ ë“±ë¡"""
        self.scrapers[platform] = scraper
        logger.info(f"âœ… {platform} ìŠ¤í¬ë˜í¼ ë“±ë¡ ì™„ë£Œ")
    
    def _get_cache_key(self, product_name: str) -> str:
        """ğŸ—ï¸ ìºì‹œ í‚¤ ìƒì„±"""
        return f"compare_{product_name.lower().replace(' ', '_')}"
    
    def _is_cache_valid(self, cache_key: str) -> bool:
        """â° ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬"""
        if cache_key not in self.cache:
            return False
        cache_time = self.cache[cache_key]['timestamp']
        return (datetime.now() - cache_time).seconds < self.cache_duration
    
    async def compare_prices(self, product_name: str) -> Optional[PriceComparison]:
        """ğŸ”¥ 4ëª° ê°€ê²© ë¹„êµ ì‹¤í–‰"""
        
        # ìºì‹œ í™•ì¸
        cache_key = self._get_cache_key(product_name)
        if self._is_cache_valid(cache_key):
            logger.info(f"ğŸ’¨ ìºì‹œì—ì„œ ë°˜í™˜: {product_name}")
            return self.cache[cache_key]['data']
        
        logger.info(f"ğŸ” {product_name} 4ëª° ê°€ê²© ë¹„êµ ì‹œì‘...")
        
        # ëª¨ë“  í”Œë«í¼ì—ì„œ ë™ì‹œ ê²€ìƒ‰
        tasks = []
        for platform, scraper in self.scrapers.items():
            task = self._search_single_platform(platform, scraper, product_name)
            tasks.append(task)
        
        # ë™ì‹œ ì‹¤í–‰ (ë³‘ë ¬ ì²˜ë¦¬)
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # ê²°ê³¼ ì •ë¦¬
        platforms = {}
        for i, result in enumerate(results):
            platform = list(self.scrapers.keys())[i]
            if isinstance(result, Exception):
                logger.error(f"âŒ {platform} ê²€ìƒ‰ ì‹¤íŒ¨: {result}")
                continue
            if result:
                platforms[platform] = result
        
        if not platforms:
            logger.warning(f"âš ï¸ {product_name} ëª¨ë“  í”Œë«í¼ì—ì„œ ê²€ìƒ‰ ì‹¤íŒ¨")
            return None
        
        # ìµœì €ê°€ ê³„ì‚°
        prices = {p: info.current_price for p, info in platforms.items() if info.current_price > 0}
        if not prices:
            return None
            
        lowest_platform = min(prices, key=prices.get)
        lowest_price = prices[lowest_platform]
        max_price = max(prices.values())
        max_saving = max_price - lowest_price
        average_price = sum(prices.values()) // len(prices)
        
        comparison = PriceComparison(
            product_name=product_name,
            platforms=platforms,
            lowest_platform=lowest_platform,
            lowest_price=lowest_price,
            max_saving=max_saving,
            average_price=average_price,
            last_updated=datetime.now()
        )
        
        # ìºì‹œ ì €ì¥
        self.cache[cache_key] = {
            'data': comparison,
            'timestamp': datetime.now()
        }
        
        logger.info(f"âœ… {product_name} ë¹„êµ ì™„ë£Œ: {lowest_platform} {lowest_price:,}ì› (ìµœì €)")
        return comparison
    
    async def _search_single_platform(self, platform: str, scraper: BaseScraper, product_name: str) -> Optional[ProductInfo]:
        """ğŸ” ë‹¨ì¼ í”Œë«í¼ ê²€ìƒ‰"""
        try:
            async with scraper:
                results = await scraper.search_product(product_name, limit=1)
                if results:
                    logger.info(f"âœ… {platform}: {results[0].current_price:,}ì›")
                    return results[0]
                else:
                    logger.warning(f"âš ï¸ {platform}: ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                    return None
        except Exception as e:
            logger.error(f"âŒ {platform} ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return None

# ì „ì—­ ë¹„êµ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
price_engine = PriceComparisonEngine()