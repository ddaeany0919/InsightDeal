import asyncio
import logging
import os
import sys
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.interval import IntervalTrigger
from apscheduler.triggers.cron import CronTrigger

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

# í˜¸í™˜ì„± íŒ¨ì¹˜ ì ìš© (Python 3.9 importlib.metadata ì˜¤ë¥˜ í•´ê²°)
try:
    from .metadata_fix import patch_importlib_metadata
    patch_importlib_metadata()
except Exception as e:
    logging.warning(f"âš ï¸ Metadata patch failed: {e}")

# âœ… ìˆ˜ì •ëœ import ê²½ë¡œ (backend. ì œê±°)
from core.notifications import notification_service
from database.session import get_db_session, create_db_session
from database.models import Deal, Product, PriceHistory, ProductPriceHistory, PriceAlert, FCMToken

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class PriceCollectionScheduler:
    """ê°€ê²© ìˆ˜ì§‘ ë° ì•Œë¦¼ ìŠ¤ì¼€ì¤„ëŸ¬"""
    
    def __init__(self):
        self.scheduler = AsyncIOScheduler(
            timezone='Asia/Seoul',
            job_defaults={
                'coalesce': False,
                'max_instances': 3,
                'misfire_grace_time': 300  # 5ë¶„
            }
        )
        self.is_running = False
        
    async def start(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        if self.is_running:
            logger.warning("âš ï¸ Scheduler already running")
            return
            
        try:
            # ì‘ì—… ë“±ë¡
            await self._register_jobs()
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
            self.scheduler.start()
            self.is_running = True
            
            logger.info("âœ… Price collection scheduler started")
            
            # ì¦‰ì‹œ í•œ ë²ˆ ì‹¤í–‰
            await self.collect_active_prices()
            
        except Exception as e:
            logger.error(f"âŒ Failed to start scheduler: {e}")
            raise
    
    async def stop(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì •ì§€"""
        if self.scheduler.running:
            self.scheduler.shutdown()
            
        self.is_running = False
        logger.info("ğŸ›‘ Price collection scheduler stopped")
    
    async def _register_jobs(self):
        """ìŠ¤ì¼€ì¤„ë§ ì‘ì—… ë“±ë¡"""
        # 1. í™œì„± ìƒí’ˆ ê°€ê²© ìˆ˜ì§‘ - 15ë¶„ë§ˆë‹¤
        self.scheduler.add_job(
            self.collect_active_prices,
            trigger=IntervalTrigger(minutes=15),
            id='collect_active_prices',
            name='Active Products Price Collection'
        )
        
        # 2. ì „ì²´ ìƒí’ˆ ê°€ê²© ìˆ˜ì§‘ - ë§¤ì‹œê°„
        self.scheduler.add_job(
            self.collect_all_prices,
            trigger=CronTrigger(minute=0),  # ë§¤ì‹œ ì •ê°
            id='collect_all_prices',
            name='All Products Price Collection'
        )
        
        # 3. ê°€ê²© ë³€ë™ ì•Œë¦¼ ì²´í¬ - 5ë¶„ë§ˆë‹¤
        self.scheduler.add_job(
            self.check_price_alerts,
            trigger=IntervalTrigger(minutes=5),
            id='check_price_alerts',
            name='Price Alert Notifications'
        )
        
        # 4. ìƒˆ ë”œ ìŠ¤í¬ë˜í•‘ - 10ë¶„ë§ˆë‹¤ (í™•ì¥ëœ ì»¤ë®¤ë‹ˆí‹° ì»¤ë²„ë¦¬ì§€)
        self.scheduler.add_job(
            self.scrape_new_deals,
            trigger=IntervalTrigger(minutes=10),
            id='scrape_new_deals',
            name='New Deal Scraping'
        )
        
        # 5. ë°ì´í„° ì •ë¦¬ - ë§¤ì¼ ìƒˆë²½ 3ì‹œ
        self.scheduler.add_job(
            self.cleanup_old_data,
            trigger=CronTrigger(hour=3, minute=0),
            id='cleanup_old_data',
            name='Database Cleanup'
        )
        
        logger.info("ğŸ“‹ Registered 5 scheduled jobs")
    
    async def collect_active_prices(self):
        """í™œì„± ì¶”ì  ìƒí’ˆë“¤ì˜ ê°€ê²© ìˆ˜ì§‘"""
        logger.info("ğŸ” Starting active price collection...")
        
        try:
            # DBì—ì„œ í™œì„± ì¶”ì  ìƒí’ˆ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            active_products = await self._get_active_tracked_products()
            
            if not active_products:
                logger.info("ğŸ“‹ No active products to track")
                return
            
            collected_count = 0
            error_count = 0
            
            for product in active_products:
                try:
                    # ê° ì‡¼í•‘ëª°ì—ì„œ ê°€ê²© ìˆ˜ì§‘
                    new_prices = await self._collect_product_prices(product)
                    
                    if new_prices:
                        # ê°€ê²© íˆìŠ¤í† ë¦¬ì— ì €ì¥
                        await self._save_price_history(product['id'], new_prices)
                        collected_count += 1
                        
                        # ê°€ê²© ë³€ë™ ì²´í¬ (5% ì´ìƒ ë³€ë™ ì‹œ ì¦‰ì‹œ ì•Œë¦¼)
                        await self._check_significant_price_change(product, new_prices)
                        
                except Exception as e:
                    logger.error(f"âŒ Error collecting price for product {product['id']}: {e}")
                    error_count += 1
                    
                # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
                await asyncio.sleep(2)
            
            logger.info(
                f"âœ… Active price collection completed: {collected_count} successful, {error_count} errors"
            )
            
        except Exception as e:
            logger.error(f"âŒ Active price collection failed: {e}")
    
    async def collect_all_prices(self):
        """ì „ì²´ ìƒí’ˆ ê°€ê²© ìˆ˜ì§‘ (ì‹œê°„ë‹¹)"""
        logger.info("ğŸ” Starting full price collection...")
        
        try:
            # ì „ì²´ ìƒí’ˆ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (í˜ì´ì§€ë„¤ì´ì…˜ ê³ ë ¤)
            all_products = await self._get_all_products(limit=100)
            
            logger.info(f"ğŸ“Š Found {len(all_products)} products to collect")
            
            collected_count = 0
            for product in all_products:
                try:
                    new_prices = await self._collect_product_prices(product)
                    
                    if new_prices:
                        await self._save_price_history(product['id'], new_prices)
                        collected_count += 1
                        
                except Exception as e:
                    logger.error(f"âŒ Error in full collection for product {product['id']}: {e}")
                
                # ë¶€í•˜ ë¶„ì‚°ì„ ìœ„í•œ ëŒ€ê¸°
                await asyncio.sleep(3)
            
            logger.info(f"âœ… Full price collection completed: {collected_count} products")
            
        except Exception as e:
            logger.error(f"âŒ Full price collection failed: {e}")
    
    async def check_price_alerts(self):
        """ê°€ê²© ì•Œë¦¼ ì²´í¬ ë° ë°œì†¡"""
        try:
            # ëª©í‘œê°€ ë„ë‹¬í•œ ìƒí’ˆë“¤ ì°¾ê¸°
            target_reached = await self._find_target_price_reached()
            
            for alert_data in target_reached:
                try:
                    user_tokens = await self._get_user_fcm_tokens(alert_data['user_id'])
                    
                    if user_tokens:
                        await notification_service.send_price_alert(
                            alert_data['product'], 
                            user_tokens
                        )
                        
                        # ì•Œë¦¼ ë°œì†¡ ê¸°ë¡ ì €ì¥
                        await self._mark_alert_sent(alert_data['alert_id'])
                        
                except Exception as e:
                    logger.error(f"âŒ Error sending price alert: {e}")
            
            if target_reached:
                logger.info(f"ğŸ“¢ Sent {len(target_reached)} price alerts")
                
        except Exception as e:
            logger.error(f"âŒ Price alert check failed: {e}")
    
    async def scrape_new_deals(self):
        """ìƒˆë¡œìš´ ë”œ ìŠ¤í¬ë˜í•‘ - í™•ì¥ëœ ì»¤ë®¤ë‹ˆí‹° ì»¤ë²„ë¦¬ì§€"""
        logger.info("ğŸ” Scraping new deals from all communities...")
        
        try:
            # âœ… ìˆ˜ì •ëœ ìŠ¤í¬ë˜í¼ import ê²½ë¡œ (backend. ì œê±°)
            from scrapers.ppomppu_scraper import PpomppuScraper
            from scrapers.ruliweb_scraper import RuliwebScraper
            from scrapers.clien_scraper import ClienScraper
            from scrapers.quasarzone_scraper import QuasarzoneScraper
            from scrapers.alippomppu_scraper import AlippomppuScraper
            from scrapers.fmkorea_scraper import FmkoreaScraper
            
            # DB ì„¸ì…˜ ìƒì„±
            db_session = create_db_session()
            
            scrapers = [
                PpomppuScraper(db_session),
                RuliwebScraper(db_session),
                ClienScraper(db_session),
                QuasarzoneScraper(db_session),
                AlippomppuScraper(db_session),
                FmkoreaScraper(db_session)
            ]
            
            total_new_deals = 0
            
            for scraper in scrapers:
                try:
                    # ê¸°ì¡´ scrape ë©”ì„œë“œ í™œìš© (ë¹„ë™ê¸° ëŒ€ì‹  ë™ê¸° í˜¸ì¶œ)
                    with scraper:
                        new_deals = scraper.run(limit=20)
                        
                        if new_deals:
                            total_new_deals += 1
                            logger.info(f"âœ… {scraper.community_name}: Found new deals")
                            
                except Exception as e:
                    logger.error(f"âŒ Scraper {scraper.__class__.__name__} failed: {e}")
            
            # DB ì„¸ì…˜ ì •ë¦¬
            db_session.close()
            
            if total_new_deals > 0:
                logger.info(f"âœ… Scraping completed: {total_new_deals}/6 scrapers successful")
            else:
                logger.info("ğŸ“‹ No new deals found from any community")
                
        except Exception as e:
            logger.error(f"âŒ Deal scraping failed: {e}")
    
    async def cleanup_old_data(self):
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ (90ì¼ ì´ìƒ)"""
        logger.info("ğŸ—‘ï¸ Starting database cleanup...")
        
        try:
            cutoff_date = datetime.now() - timedelta(days=90)
            
            # DB ì„¸ì…˜ì„ ì‚¬ìš©í•˜ì—¬ ì •ë¦¬ ì‘ì—…
            with create_db_session() as session:
                # ì˜¤ë˜ëœ ê°€ê²© íˆìŠ¤í† ë¦¬ ì‚­ì œ
                deleted_prices = session.query(PriceHistory).filter(
                    PriceHistory.checked_at < cutoff_date
                ).count()
                
                session.query(PriceHistory).filter(
                    PriceHistory.checked_at < cutoff_date
                ).delete(synchronize_session=False)
                
                session.commit()
                
            logger.info(
                f"âœ… Cleanup completed: {deleted_prices} price records deleted"
            )
            
        except Exception as e:
            logger.error(f"âŒ Database cleanup failed: {e}")
    
    # Helper methods
    
    async def _get_active_tracked_products(self) -> List[Dict]:
        """í™œì„± ì¶”ì  ìƒí’ˆ ëª©ë¡ ì¡°íšŒ"""
        try:
            with create_db_session() as session:
                products = session.query(Product).filter(
                    Product.is_tracking == True
                ).all()
                
                return [
                    {
                        "id": p.id,
                        "product_id": p.product_id,
                        "url": p.url,
                        "title": p.title,
                        "current_price": p.current_price,
                        "target_price": p.target_price,
                        "user_id": p.user_id
                    }
                    for p in products
                ]
        except Exception as e:
            logger.error(f"âŒ Failed to get active products: {e}")
            return []
    
    async def _get_all_products(self, limit: int = 100) -> List[Dict]:
        """ì „ì²´ ìƒí’ˆ ëª©ë¡ ì¡°íšŒ"""
        try:
            with create_db_session() as session:
                products = session.query(Product).limit(limit).all()
                return [
                    {
                        "id": p.id,
                        "url": p.url,
                        "title": p.title
                    }
                    for p in products
                ]
        except Exception as e:
            logger.error(f"âŒ Failed to get all products: {e}")
            return []
    
    async def _collect_product_prices(self, product: Dict) -> Optional[Dict]:
        """íŠ¹ì • ìƒí’ˆì˜ 4ëª° ê°€ê²© ìˆ˜ì§‘"""
        # TODO: ì‹¤ì œ ìŠ¤í¬ë˜í¼ ì—°ë™ (í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜ ë¡œì§)
        # ì‹¤ì œ êµ¬í˜„ì‹œì—ëŠ” product['url']ì„ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ ìŠ¤í¬ë˜í¼ ì„ íƒ í•„ìš”
        return None
    
    async def _save_price_history(self, product_id: int, prices: Dict):
        """ê°€ê²© íˆìŠ¤í† ë¦¬ ì €ì¥"""
        try:
            with create_db_session() as session:
                # 1. ProductPriceHistory ì¶”ê°€
                history = ProductPriceHistory(
                    product_id=product_id,
                    price=prices.get('price', 0),
                    is_available=prices.get('is_available', True)
                )
                session.add(history)
                
                # 2. Product í˜„ì¬ê°€ ì—…ë°ì´íŠ¸
                product = session.query(Product).filter(Product.id == product_id).first()
                if product:
                    product.current_price = prices.get('price', 0)
                    product.last_checked = datetime.now()
                    
                    # ìµœì €ê°€ ê°±ì‹  ë¡œì§
                    if not product.lowest_price or product.current_price < product.lowest_price:
                        product.lowest_price = product.current_price
                
                session.commit()
        except Exception as e:
            logger.error(f"âŒ Failed to save price history: {e}")
    
    async def _check_significant_price_change(self, product: Dict, new_prices: Dict):
        """ìœ ì˜ë¯¸í•œ ê°€ê²© ë³€ë™ ì²´í¬ (5% ì´ìƒ)"""
        if not product.get('current_price'):
            return
            
        old_price = product['current_price']
        new_price = new_prices.get('price', 0)
        
        if new_price == 0: return
        
        # 5% ì´ìƒ í•˜ë½ ì‹œ
        if new_price < old_price * 0.95:
            logger.info(f"ğŸ“‰ Price drop detected for {product['title']}: {old_price} -> {new_price}")
            # ì•Œë¦¼ ë°œì†¡ ë¡œì§ í˜¸ì¶œ ê°€ëŠ¥
            
    async def _find_target_price_reached(self) -> List[Dict]:
        """ëª©í‘œê°€ ë„ë‹¬í•œ ì•Œë¦¼ ì°¾ê¸°"""
        try:
            with create_db_session() as session:
                # PriceAlert í…Œì´ë¸”ê³¼ Product í…Œì´ë¸” ì¡°ì¸
                alerts = session.query(PriceAlert).join(Product).filter(
                    PriceAlert.is_active == True,
                    Product.current_price <= PriceAlert.target_price
                ).all()
                
                return [
                    {
                        "alert_id": a.id,
                        "user_id": a.user_id,
                        "product": {
                            "title": a.product.title,
                            "price": a.product.current_price,
                            "url": a.product.url
                        }
                    }
                    for a in alerts
                ]
        except Exception as e:
            logger.error(f"âŒ Failed to find target price alerts: {e}")
            return []
    
    async def _get_user_fcm_tokens(self, user_id: str) -> List[str]:
        """ì‚¬ìš©ì FCM í† í° ì¡°íšŒ"""
        try:
            with create_db_session() as session:
                tokens = session.query(FCMToken.token).filter(
                    FCMToken.user_id == user_id,
                    FCMToken.is_active == True
                ).all()
                return [t[0] for t in tokens]
        except Exception as e:
            logger.error(f"âŒ Failed to get FCM tokens: {e}")
            return []
    
    async def _mark_alert_sent(self, alert_id: int):
        """ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ í‘œì‹œ"""
        try:
            with create_db_session() as session:
                alert = session.query(PriceAlert).filter(PriceAlert.id == alert_id).first()
                if alert:
                    alert.last_triggered = datetime.now()
                    alert.trigger_count += 1
                    session.commit()
        except Exception as e:
            logger.error(f"âŒ Failed to mark alert sent: {e}")

async def main():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    scheduler = PriceCollectionScheduler()
    
    try:
        await scheduler.start()
        
        logger.info("â° Enhanced scheduler with 6 communities running... Press Ctrl+C to stop")
        
        # ë¬´í•œ ëŒ€ê¸° (Ctrl+Cë¡œ ì¢…ë£Œ)
        while True:
            await asyncio.sleep(60)
            
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ Received shutdown signal")
    except Exception as e:
        logger.error(f"âŒ Scheduler crashed: {e}")
    finally:
        await scheduler.stop()
        logger.info("ğŸ‘‹ Enhanced scheduler shut down gracefully")

if __name__ == "__main__":
    asyncio.run(main())
